[["index.html", "Chapter 1 简介与传送门 1.1 简介 1.2 传送门", " Chapter 1 简介与传送门 日期: 2020-11-10 作者：wxhyihuan 1.1 简介 这份笔记主要是我个人在学习孙振球，徐勇勇老师的&lt;&gt; 第4版的过程中，尽量使用编程语言R对书中的示例进行实现的记录， 并用Bookdown形成的。 &lt;&lt;医学统计学&gt;&gt; 孙振球, 徐勇勇. 第4版[M]. 人民卫生出版社, 2014. 虽然在学习，整理过程中尽量将笔记的形式，内容结构进行力所能及的梳理，这里要特别感谢在学习过程中，在网络上找到的一些参考资料带来的帮助，然后将一些 示例与原书进行对照，以避免一些学习错误，但个人能力和精力实在有限，也容易会有理解错误，表述不当，内容专业的错误， 如果您在参考的过程中，发现了这样的错误，请您尽量可以告诉我，我会确认并努力修正。如果您对文档有疑问或建议，可以 邮件 告知我。 建议您购买原版教材结合本笔记学习，您也可以在网络上找到电子书方便参考。 形成此文档对我来讲是一个很大的挑战，需要耗费巨大精力。另外，因本人生患病，难以像以前正常工作，所以也是以此方式 保持学习能力，和提升自己。希望这份文档能对您有所助益，如果正是如此，您可以捐助我，这里先谢过鼓励和支持的朋友~ 最后，祝愿来过此处的你我他！ 1.1.1 软件准备 本文档使用到的主要软件 R版本是4.0.3, 和 RStudio，版本是 1.3.1093 . 如果您R语言的新手，您可以在下面找到一些快速学习的资料： RStudio Cheatsheets R for Beginners sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 19041) ## Matrix products: default ## locale: ## [1] LC_COLLATE=Chinese (Simplified)_China.936 ## [2] LC_CTYPE=Chinese (Simplified)_China.936 ## [3] LC_MONETARY=Chinese (Simplified)_China.936 ## [4] LC_NUMERIC=C ## [5] LC_TIME=Chinese (Simplified)_China.936 ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## loaded via a namespace (and not attached): ## [1] compiler_4.0.3 bookdown_0.21 htmltools_0.5.0 tools_4.0.3 ## [5] yaml_2.2.1 tinytex_0.27 rmarkdown_2.5 knitr_1.30 ## [9] digest_0.6.27 xfun_0.19 rlang_0.4.8 evaluate_0.14 1.2 传送门 如果您希望快速找到R处理数据的方法，可以通过下面几张插图里面的传送门进行传送。注意的是，似乎Rmarkdown里面对 插图中包含链接展示无法很好支持，所以你需要 “右击”插图，选择在 “新标签页打开图片”，然后新标页签打开的图片 包含有超链接，可以帮您快速找到合适的章节。 Figure 1.1: 完全随机设计的统计方法选择思路(目前, 传送门还不完整，在随书更新ing) "],["第二章-计量资料的统计描述.html", "Chapter 2 第二章 计量资料的统计描述 2.1 描述统计 2.2 测试数据 2.3 数据输入和频率统计 2.4 描述性统计的度量 2.5 正态分布和标准正态分布 2.6 其他的描述统计", " Chapter 2 第二章 计量资料的统计描述 日期: 2020-11-10 作者：wxhyihuan 2.1 描述统计 描述统计学(广义上的描述统计学)是统计学的一个分支，旨在概括、描述和呈现一系列值或数据集(比如对单样本的分析)。 由于难以识别数据中的任何模式，没有任何准备或没有任何汇总度量的长系列值通常无法提供信息。 描述统计通常是统计分析的第一步，也是统计分析的重要组成部分。它允许通过检测潜在的异常值(即似乎与其他数据分离的数据点)、 收集或编码错误来检查数据的质量。它还有助于“理解”数据，如果表述得当，描述性统计是进一步分析的一个很好的起点。 位置与离散度量是两种不同的总结数据的测量方法。其中一些给出了关于数据位置的理解，另一些给出了关于数据分散性的理解。 在实践中，这两种度量方法经常一起使用，以便以最简洁和完整的方式总结数据。 位置度量允许查看数据位于“何处”，围绕哪个值。换句话说，位置度量可了解什么是总体趋势，即数据整体的“位置”。 它主要包括：平均值，中位数，四分位数，第三、四分位数，众数，最大值，最小值等。 常见的离散度量，它有助于了解离散度和数据的可变性(在何种程度上分布被压缩或拉伸):范围，标准偏差，方差，四分位间距，变异系数。 2.2 测试数据 Table 2.1: 某医院用随机抽样的方法检测了138名正常成年女子的红细胞数目(RBC， \\(*10^{12}/L\\)),其测量结果如下表： V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 3.96 4.23 4.42 3.59 5.12 4.02 4.32 3.72 4.76 4.16 4.61 4.26 3.77 4.20 4.36 3.07 4.89 3.97 4.28 3.64 4.66 4.04 4.55 4.25 4.63 3.91 4.41 3.52 5.03 4.01 4.30 4.19 4.75 4.14 4.57 4.26 4.56 3.79 3.89 4.21 4.95 3.98 4.29 3.67 4.69 4.12 4.56 4.26 4.66 4.28 3.83 4.20 5.24 4.02 4.33 3.76 4.81 4.17 3.96 3.27 4.61 4.26 3.96 4.23 3.76 4.01 4.29 3.67 3.39 4.12 4.27 3.61 4.98 4.24 3.83 4.20 3.71 4.03 4.34 4.69 3.62 4.18 4.26 4.36 5.28 4.21 4.42 4.36 3.66 4.02 4.31 4.83 3.59 3.97 3.96 4.49 5.11 4.20 4.36 4.54 3.72 3.97 4.28 4.76 3.21 4.04 4.56 4.25 4.92 4.23 4.47 3.60 5.23 4.02 4.32 4.68 4.76 3.69 4.61 4.26 3.89 4.21 4.36 3.42 5.01 4.01 4.29 3.68 4.71 4.13 4.57 4.26 4.03 5.46 4.16 3.64 4.16 3.76 2.3 数据输入和频率统计 2.3.1 读取数据，并将数据转换成单列形式 RBC&lt;-read.table(&quot;ExampleData/02-01.txt&quot;,sep=&quot;\\t&quot;) RBC&lt;-as.matrix(RBC) RBC_q &lt;- c() for (i in seq(1:nrow(RBC))){ RBC_q &lt;- c(RBC_q, RBC[i,]) } RBC_v&lt;-as.vector(RBC_q) RBC_v&lt;-na.omit(RBC_v) 2.3.2 计算极差, max()/min()/range() #range(RBC_v) 返回最小值和最大值 rge&lt;-max(RBC_v)-min(RBC_v) rge ## [1] 2.39 2.3.3 确定组段数和组距 可以参考PAST软件中的the zero-stage rule of Wand 1997方式计算分段“最佳”个数。\\(h=3.49min(s,IQ/1.349)n^{1/3}\\)，其中s是样本标准差，IQ是四分位数范围。 #sd()计算标准差，quantile()计算分位数 s&lt;-sd(RBC_v) ## [1] 0.4457298 quan&lt;-quantile(RBC_v,c(0.25,0.75)) iq&lt;-quan[2]-quan[1] ## 0.565 h&lt;-3.49*min(s,iq/1.349)*(length(RBC_v)^(1/3)) ## 7.553617 h&lt;-ceiling(h) ## 8 i&lt;-rge/h 2.3.4 计算频数分布 根据计算的短组段数(h=8)，极差值(rge=2.39))和组距(i=rge/h=0.3164)计算各组段的频数。 breaks = seq(min(RBC_v), max(RBC_v), length.out = 8) RBC_v.cut = cut(RBC_v, breaks, right=T,include.lowest=T) RBC_v.freq = table(RBC_v.cut) ## [3.07,3.41) [3.41,3.75) [3.75,4.09) [4.09,4.44) [4.44,4.78) ## 4 17 29 51 23 ## [4.78,5.12) [5.12,5.46) ## 9 4 hist(RBC_v, right=FALSE, breaks = breaks, labels =TRUE, freq = TRUE, col = &quot;#A8D6FF&quot;, border = &quot;white&quot;, ylim=c(0, max(RBC_v.freq))) hist(RBC_v, right=FALSE, breaks = breaks, labels =TRUE, freq = FALSE, col = &quot;#A8D6FF&quot;, border = &quot;white&quot;, ylim=c(0,1)) lines(density(RBC_v),col=&quot;red&quot;,lwd=2) Figure 2.1: 红细胞含量的频数分布 2.4 描述性统计的度量 2.4.1 算术平均值 算术均数简称均值(mean),用于反映组呈对称分布的变量值在数量上的平均水平。 mean(RBC_v) ## [1] 4.227029 2.4.2 几何平均值 几何均数(geometric mean)可用于反映一组经 对数转换 后呈对称分布的变量值在数量上的平均水平。 exp(mean(log(RBC_v))) ## [1] 4.203676 2.4.3 中位数与百分位数 中位数(median)是将n个变量值从小到大排列,位置居于中间的那个数。当为奇数时取位次居中 的变量值,当n为偶数时取位次居中的两个变量值的均数。 它适用于各种分布类型的资料,尤其是偏态分 布资料和一端或两端无确切数值的资料。 #中位数（=50百分位） median(RBC_v) quantile(RBC_v, 0.5) ## 4.23 #百分位 quantile(RBC_v, c(0.1, 0.25, 0.5,0.75,0.9)) ## 10% 25% 50% 75% 90% ##3.6670 3.9625 4.2300 4.5275 4.7750 2.4.4 极差 极差即一组变量值的最大值与最小值之差。 max(RBC_v)-min(RBC_v) range(RBC_v) 2.4.5 四分位间距(interquartile range) 四分位数(quartile)是把全部变量值分为四部分的分位数,即第1四分位数(Q .=Ps)、第2四分位数 M=P)、第3四分位数 (Qu=Ps)。 四分位数间距(quartile range)是由第3四分位数和第1四分位数相减行得, 记为 R.它般和中位数起描述偏态分们资料的分布特征 IQR(RBC_v) ## 0.565 quantile(RBC_v, 0.75)-quantile(RBC_v, 0.25) ## 0.565 2.4.6 方差与标准差 方差(variance，var)也称均方差(mean Square deviation)，反映一组数据的平均离散水平。 标准差(standard deviation，sd)是方差的正平方根,其单位与原变量值的单位相同。 #计算标准差 sd(RBC_v) ## [1] 0.4457298 #计算方差 var(RBC_v) ## [1] 0.1986751 sd(RBC_v)^2 (sum((RBC_v-mean(RBC_v))^2))/(length(RBC_v)-1) ## 0.1986751 2.4.7 变异系数 变异系数(Cefficient of variation，CV)，当进行两个或多个资料变异程度的比较时，如果度量单位与平均数相同， 可以直接利用标准差来比较。如果单位和（或）平均数不同时，比较其变异程度就不能采用标准差， 而需采用标准差与平均数的比值（相对值）来比较。标准差与平均数的比值称为变异系数，。 变异系数可以消除单位和（或）平均数不同对两个或多个资料变异程度比较的影响。 sd(RBC_v)/mean(RBC_v)*100 ## [1] 10.54475 raster::cv(RBC_v) ## [1] 10.54475 2.5 正态分布和标准正态分布 正态分布（Normal distribution）又名高斯分布（Gaussian distribution），是一个非常常见的连续概率分布。 正态分布在统计学上十分重要，经常用在自然和社会科学来代表一个不明的随机变量。 可以说，弄懂正态分布是灵活运用统计学中各种假设检验方法、理解p值，均数置信区间的前提。 R包含有很丰富的正态分布相关的函数功能， 比如概率密度函数dnorm()，概率累积分布函数pnorm()，正态分位函数qnorm()和用来生成特定正态分布数据序列的函数rnorm()， 以及检测数据时候符合正态分布的方法，这里主要做下面一些介绍。 2.5.1 概率密度函数dnorm() 概率密度函数（Probability density function），R中即为dnorm()， 它可以给出了指定均值和标准差下每个点的概率分布的高度， 越高就代表着这个点/区间的概率越密集(大)。概率密度函数有时也被称为概率分布函数，但这种称法可能会和累积分布函数pnorm()混淆。 #在-10~10区间等分的 100个 数据集x x &lt;- seq(-10, 10, by = .1) #创建一个均值是2.5，标准差是0.5正态分布 y y &lt;- dnorm(x, mean = 2.5, sd = 0.5) #将 y 中的落在x数据集上的数据画出来 plot(x,y,col=&quot;red&quot;,pch=20) Figure 2.2: 概率密度函数示例 2.5.2 概率累积分布函数pnorm() 累积分布函数（Cumulative Distribution Function），R中即为pnorm()， 又叫分布函数，是概率密度函数的积分，能完整描述一个实随机变量X的概率分布，它给出一个正态分布中小于一个给定数字的累计概率(即指定定点的左边范围的曲线面积)。 #在-10~10区间等分的 40个 数据集x x &lt;- seq(-10, 10, by = .5) #创建一个均值是2.5，标准差是0.5正态分布 y y &lt;- pnorm(x, mean = 2.5, sd = 0.5) #将 y 中的落在x数据集上的累计概率画出来 plot(x,y,col=&quot;red&quot;,pch=20) Figure 2.3: 累积分布函数示例 2.5.3 正态分位函数qnorm() 正态分位函数，R中即为qnorm()，它可以给出一个累积分布概率达到指定值的数字。 #在0~1区间等分的 50个 数据集x x &lt;- x &lt;- seq(0, 1, by = 0.02) #创建一个均值是2，标准差是1正态分布 y y &lt;- qnorm(x, mean = 2, sd = 1) #将 y 中的落在x数据集上的数字画出来 plot(x,y,col=&quot;red&quot;,pch=20) Figure 2.4: 正态分位函数示例 2.5.4 指定正态分布函数rnorm() rnorm()函数用于生成符合指定均值和标准差的分布为正态分布的随机数，默认是标准正态分布，即均值为0，标准差1的正态分布。 #设置随机种子，便于重复后续的数据选取 set.seed(50) #在标准正态分布中随机选取50个数据 y &lt;- rnorm(50) #对选区的数据绘制频率分布图 hist(y,col=&quot;#A8D6FF&quot;,labels =TRUE) Figure 2.5: 随机正态分布数据示例 2.5.5 正态分布检验 许多计量资料的分析方法要求数据分布是正态或近似正态，因此对原始独立测定数据进行正态性检验是十分必要的。通过绘制数据的频数分布直方图来定性地判断数据分布正态性。 以下正态检验的资料整理自： 用R语言做正态分布检验 How to test the normality assumption 正态性检验主要有三类方法: 计算综合统计量 如动差法、夏皮罗-威尔克Shapiro-Wilk 法(W 检验) 、达戈斯提诺D′Agostino 法(D 检验) 、Shapiro-Francia 法(W′检验)。 正态分布的拟合优度检验 如皮尔逊χ2 检验 、对数似然比检验 、柯尔莫哥洛夫Kolmogorov-Smirov 法检验。 图示法(正态概率图Normal Probability plot) 如分位数图(Quantile Quantileplot ,简称QQ 图) 、百分位数(Percent Percent plot ,简称PP 图) 和稳定化概率图(Stablized Probability plot , 简称SP 图) 等。 统计软件中常用的正态性检验方法 用偏态系数和峰态系数检验数据正态性 偏态系数Sk,它用于检验不对称性;峰态系数Ku,它用于检验峰态。 S k= 0, K u= 0 时, 分布呈正态, S k&gt; 0 时, 分布呈正偏态,S k &lt; 0 时, 分布呈负偏态。适用条件：样本含量应大于200 用夏皮罗-威尔克(Shapiro-Wilk)法检验数据正态性 即W检验,1965 年提出,适用于样本含量n 50 时的正态性检;。 用达戈斯提诺(D′Agostino)法检验数据正态性 即D检验,1971提出,正态性D检验该方法效率高，是比较精确的正态检验法。 Shapiro-Francia 法 即W′检验,于1972 年提出,适用于50 &lt; n &lt; 100 时的正态性检验。 QQ图或PP图 散点聚集在固定直线的周围，可以认为数据资料近似服从正态分布 常用的规则： SPSS 规定:当样本含量3 n 5000 时,结果以Shapiro - Wilk (W 检验) 为难,当样本含量n &gt; 5000 结果以Kolmogorov - Smirnov 为准。 SAS 规定:当样本含量n 2000 时,结果以Shapiro - Wilk (W 检验) 为准,当样本含量n &gt;2000 时,结果以Kolmogorov - Smirnov (D 检验) 为准。 参考： 刘庆武,胡志艳，如何用SPSS、SAS 统计软件进行正态性检验，湘南学院学报(自然科学版)，2005 朱红兵，何丽娟，在SPSS10.0 中进行数据资料正态性检验的方法，首都体育学院学报，2004 2.5.5.1 直方图 直方图显示了分布的分布范围和形状，因此它是评估正态性的一个很好的起点。本文开始测试的红细胞浓度遵循正态曲线，因此数据似乎遵循正态分布。 hist(RBC_v, right=FALSE, breaks = breaks, labels =TRUE, freq = FALSE, col = &quot;#A8D6FF&quot;, border = &quot;white&quot;, ylim=c(0,1)) lines(density(RBC_v),col=&quot;red&quot;,lwd=2) Figure 2.6: 正态分布检验与直方图 2.5.5.2 密度图 密度图提供了关于数据是否服从正态分布的直观判断。它们类似于直方图，因为它们也允许分析分布的传播和形状。但是，它们是直方图的平滑版本。 maintxt&lt;-paste(&quot;N=&quot;,length(RBC_v),&quot;,&quot;,&quot;Mean=&quot;,round(mean(RBC_v),3),&quot;,&quot;,&quot;Sd=&quot;,round(s,3)) plot(density(RBC_v),col=&quot;red&quot;,lwd=2,main = maintxt) Figure 2.7: 正态分布检验与密度图 2.5.5.3 QQ-plot 有的数据从直方图和密度图很难检验正态性，因此建议用qq图来确证这些图。QQ-plot，又称正态图。在QQ-plots中， 我们只需要确定数据点是否沿着直线(有时也称为Henry’s line)，而不是查看数据的扩散情况(如直方图和密度图)。 如果点靠近参考线并且在置信区间内，则认为满足了正态性假设。点与参考线之间的偏差越大，偏离置信区间越远， 满足正态条件的可能性就越小。这12个成年人的身高似乎服从正态分布，因为所有的点都在置信区间内。 如果qq图所示的非正态分布(系统地偏离参考线)时，通常第一步是对数据进行对数变换， 并重新检查对数变换后的数据是否正态分布。可以应用log()函数进行对数变换。 另外，qq图也是评估回归分析的残差是否服从正态分布的一种方便的方法。 Figure 2.8: 难以判断正态分布的密度图 #qqPlot是car包中的函数，因此需要载入包 library(car) ## Loading required package: carData set.seed(42) dat_hist &lt;- data.frame( value = rnorm(12, mean = 165, sd = 5)) ## qqPlot(dat_hist$value) Figure 2.9: 正态分布检验与QQ-plot (1) ## [1] 12 2 #qqPlot是car包中的函数，因此需要载入包 library(car) qqPlot(as.numeric(RBC_v),ylab=&quot;RBC&quot;, main=&quot;RBC QQ-plot&quot;) Figure 2.10: 正态分布检验与QQ-plot (2) 2.5.5.4 正态检验 上述3种方法是对常态的目视检查。然而，目测有时可能不可靠，因此也有可能通过统计检验正式检验数据是否服从正态分布。 这些正态性检验将数据的分布与正态分布进行比较，以评估观察结果是否显示出偏离正态性的重要偏差。 最常用的两种正态性检验是Shapiro-Wilk检验（K检验）和Kolmogorov-Smirnov检验（D检验）。两种测试都有相同的假设，即: H0 : 数据服从正态分布 H1 : 数据不服从正态分布 正态性检验推荐使用Shapiro-Wilk检验，因为它比Kolmogorov-Smirnov检验提供更好的效用。 在R中，正态性的Shapiro-Wilk检验可以通过函数shapiro.test()进行。 set.seed(42) dat_hist &lt;- data.frame( value = rnorm(12, mean = 165, sd = 5)) shapiro.test(dat_hist$value) ## Shapiro-Wilk normality test ## ## data: dat_hist$value ## W = 0.9, p-value = 0.5 从输出中，我们看到p-value&gt;0.05意味着我们不拒绝数据服从正态分布的原假设。 该检验与qq图的方向相同，qq图与正态性没有显著偏差(因为所有点都在置信区间内)。 shapiro.test(RBC_v) ## Shapiro-Wilk normality test ## ## data: as.numeric(RBC_v) ## W = 1, p-value = 0.4 对RBC数据同样的结果。 注意的是，在实践中，正态检验通常被认为过于保守，因为对于大样本(n&gt;50)，对正态条件的一个 小偏差可能会导致违反正态判断的条件。由于正态性检验是一种假设检验，所以随着样本量的增加，其检测较小差 异的能力也会增加。因此，随着观测数的增加，Shapiro-Wilk检验变得非常敏感，甚至对正态性的一个 微小偏差也非常敏感。所以，根据正态性检验，数据不服从正态分布，尽管偏离正态分布的情况可以忽略不计，但数据 实际上服从正态分布。因此，通常情况下，正态性条件的验证是基于本文所介绍的所有方法的组合，即目视检验 (使用直方图和q-q图)和正式化检验(例如使用shapio-wilk检验)。 R中还有其他一些正态检验的方法，比如 ks.test() 函数实现Kolmogorov-Smirnov Test（D检验）， 是对经验分布的拟合检验，检验的是经验分布函数和假设总体分布函数的差异，适应于大样本(n&gt;5000)。 另外有一些package包含了丰富的检验函数，比如fBasics，nortest等。 2.6 其他的描述统计 2.6.1 Summary 您可以计算最小，第1四分位数，中位数，平均值，第3，4分位数和最大值的数据集的所有数值变量使用summary(): dat &lt;- iris summary(dat) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 setosa :50 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 versicolor:50 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 virginica :50 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 2.6.2 众数 众数（Mode）是指在统计分布上具有明显集中趋势点的数值，代表数据的一般水平。 也是一组数据中出现次数最多的数值，有时众数在一组数中有好几个。 可以利用table()和sort()来寻找数据集中的众数。 # 计算每个元素的出现的次数 RBC_t &lt;- table(RBC_v) # 对计算的次数进行排序 sort(RBC_t, decreasing = TRUE) ## 4.26 4.36 3.96 4.02 4.2 3.76 3.97 4.01 4.16 4.21 4.23 4.28 4.29 4.56 4.61 4.76 ## 7 5 4 4 4 3 3 3 3 3 3 3 3 3 3 3 ## 3.59 3.64 3.67 3.72 3.83 3.89 4.03 4.04 4.12 4.25 4.32 4.42 4.57 4.66 4.69 3.07 ## 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 ## 3.21 3.27 3.39 3.42 3.52 3.6 3.61 3.62 3.66 3.68 3.69 3.71 3.77 3.79 3.91 3.98 ## 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## 4.13 4.14 4.17 4.18 4.19 4.24 4.27 4.3 4.31 4.33 4.34 4.41 4.47 4.49 4.54 4.55 ## 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## 4.63 4.68 4.71 4.75 4.81 4.83 4.89 4.92 4.95 4.98 5.01 5.03 5.11 5.12 5.23 5.24 ## 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## 5.28 5.46 ## 1 1 #或者结合 which()函数确定众数和其次数 RBC_t[which(((RBC_t==max(RBC_t))==T))] ## 4.26 ## 7 "],["第三章-总体均数的估计与假设检验.html", "Chapter 3 第三章 总体均数的估计与假设检验 3.1 推论统计 3.2 t 分布 3.3 t 检验 3.4 变量转换", " Chapter 3 第三章 总体均数的估计与假设检验 日期: 2020-11-14 作者：wxhyihuan 3.1 推论统计 推论统计（或称统计推断，Statistical inference），指统计学中，研究如何根据样本数据去推断总体数量特征的方法。 它是在对样本数据进行描述的基础上，对统计总体的未知数量特征做出以概率形式表述的推断。更概括地说， 是在一段有限的时间内，通过对一个随机过程的观察来进行推断的。统计学中，统计推断与描述统计相对应。 推论统计(Statistical inferences)是借助抽样调查，从局部推断总体，以对不肯定的事物做出决策的一种统计。 有总体参数估计与假设检验两种。前者以一次性抽样实验为依据，对整个总体的某个数字特征做出估计。后者则是对 某种假设进行检验，根据计算结果推断所做的假设是否可以接受。如平均数、标准差、相关系数、回归系数等特征的 总体估计及差异显著性检验。推断统计的理论基础是概率论，它更多地需要借助抽样理论与方法。 3.1.1 参数估计与假设检验 参数估计背后的思想是通过对从总体中抽取的样本进行统计显著性检验(如t检验)，为研究人员提供关于总体的统计推断。 被称为t检验的参数检验是基于W.S.Gosset的t统计量，该统计数据假设变量来自正态总体。t检验统计量中的总体均值是已知的。 这种分布称为t分布，其形状与正态分布类似，即钟形曲线。t检验用于检验那些样本小于30的样本比正态分布要好， 在大样本上做的和正态分布一样好。 假设检验(Hypothesis test)过去也叫做显著性检验(Significance test)，是利用小概率反证法思想，从问题的对立面(\\(H_0\\))出发， 间接判断解决问题(\\(H_1\\))是否成立。即在假设\\(H_0\\)成立的条件下，计算检验统计量(Test static)，然后根据\\(P\\)值(P-value)来判断。 3.1.2 统计量与标准误 样本是总体的代表和反映，也是统计推断的依据，为了对总体的分布或数字特征进行各种统计推断，还需要对样本作加工处理， 把样本中应关心的事物和信息集中起来，针对不同的问题构造出样本的不同函数(如均值，方差，极差，标准差，中位数，众数等)，这种样本的函数我们称其为统计量。 样本统计量的标准差即为标准误(Stand error,SE)，反映了抽样的统计量的离散程度或误差大小。如样本均数的标准差也称为均数标准误 (Stand error of mean, SEM)，SEM反映了样本均数的离散程度。 3.2 t 分布 若某一随机变量X服从总体均数为μ，总体标标准差为σ的正态分布\\(N(μ，σ^2)\\)，通过u变换(也称Z变换)可将一般正态分布 转化为标准正态分布\\(N(0，1^2)\\)，即u分布（也称Z分布）。同理，若样本含量为n的样本均数 \\(\\bar{X}\\) 服从总体均数为μ， 总体标准差为\\(σ_\\bar{x}\\)的正态分布\\(N(μ，σ_\\bar{x}^2)\\)，则可通过u变换(\\(\\frac{\\bar{X}-μ}{σ_\\bar{x}}\\))将其转换为标准正态分布。 但是，实际中总体标准差(\\(σ_\\bar{x}\\))是未知的，所以用均数标准误的估计值（\\(S_\\bar{x}=\\frac{S}{\\sqrt{n}}\\)，其中S为样本标准差）代替， 这就使得(\\(\\frac{\\bar{X}-μ}{S_\\bar{x}}\\))不再是标准正态分布，而是服从t-分布（t-distribution）， 即： \\[t=\\frac{\\bar{X}-μ}{S_\\bar{x}}=\\frac{\\bar{X}-μ}{\\frac{S}{\\sqrt{n}}}\\] t-分布 对应的概率密度函数是： \\[f(x)=\\frac{\\Gamma(\\frac{v+1}{2})}{\\sqrt{v\\pi}\\Gamma(\\frac{v}{2})}{\\left(1+\\frac{x^2}{v}\\right)^\\frac{-v+1}{2}}\\] 其中\\(\\Gamma\\)是伽马函数(Gamma function)，\\(v\\)是自由度(Degree of freedom，df)。 自由度(df)在数学上只能自由取值的变量个数，如\\(X+Y+Z=1\\)，有3个变量，但是能够自由取值的自由两个，故其自由度\\(v=2\\)。 在统计学中，自由度计算方式为： \\[v=n-m\\] 其中n为计算某一统计量是用到的数据个数，m为计算该统计量是用到的其他独立统计量个数。比如根据肿瘤位置，大小，组织活检，生化指标 判断肿瘤的类型是A，也可能是B，这里有\\(n=4\\)个独立的信息，和\\(m=2\\)个估计，所以自由度就是\\(df=4-2=2\\)。一般的希望估计（推测）的越可靠， 当然是自由度越大越好了。 t分布是一簇曲线，其形态变化与n（即其自由度）大小有关。自由度n越小，t分布曲线越低平；自由度n越大，t分布曲线越接近标准正态分布（u分布） 曲线，当自由度无限大时，t分布就成了正态分布。 3.2.1 概率密度函数dt() R中，t分布的概率密度函数为dt()，它可以给出了指定均值和标准差下每个点的概率分布的高度， 越高就代表着这个点/区间的概率越密集(大)。从下免得概率密度图见，当df=20时，t分布曲线已经非常接近标准正态曲线了。 curve(dnorm(x),xlim=c(-5,5),ylim=c(0,0.45),ylab=&quot;Student&#39;s t Density&quot;,col=&quot;red&quot;,lty=1,lwd=2) abline(v=0,lwd=1,col=&quot;black&quot;) curve(dt(x,1),col=&quot;green&quot;,lty=2,add=TRUE) curve(dt(x,2),col=&quot;brown&quot;,lty=3,add=TRUE) curve(dt(x,5),col=&quot;blue&quot;,lty=4,add=TRUE) curve(dt(x,20),col=&quot;dark green&quot;,lty=5,add=TRUE) legend(2,0.38,c(&quot;normal&quot;,&quot;df=1&quot;,&quot;df=2&quot;,&quot;df=5&quot;,&quot;df=20&quot;), col=c(&quot;red&quot;,&quot;green&quot;,&quot;brown&quot;,&quot;blue&quot;,&quot;dark green&quot;),lty=1:5) Figure 3.1: t分布检验与正态分布 3.2.2 概率累积分布函数pt() 同所有连续数值型分布一样，统计应用中最关心的是分布曲线下的尾部面积（即概率\\(P\\)或α）与横轴间的关系。 R中即为pt()，它给出一个正态分布中小于一个给定数字的累计概率(即指定定点的左边范围的曲线面积)。 一侧尾部面积称为单侧概率或单尾概率(one-tailed probability，\\(t_{α,v}\\))，两侧尾部的面积之和称为双侧概率或双尾概率 （two-tailes probability，\\(t_{α/2,v}\\)）。 单侧的p值计算 # t-stat=1.9, df=5 # 单侧 p值 # P(t =&gt; 1.9) pt(q=1.9, df=5, lower.tail = F) ## [1] 0.05793165 双侧的p值计算 ## 双侧 p-value ## 两边对称单侧相加 pt(q=1.9, df=5, lower.tail = F) + pt(q=-1.9, df=5, lower.tail = T) ## 0.1158633 ## 单侧p值*2，对称性 pt(q=1.9, df=5, lower.tail = F)*2 ## 0.1158633 # x坐标序列向量 x_pt &lt;- seq(- 5, 5, by = 0.1) # 用pt()函数获取df=5的x累计密度值 y_pt &lt;- pt(x_pt, df = 5) # Plotting plot(y_pt, type = &quot;l&quot;, main = &quot;t-distribution cumulative function example&quot;, las=1, col=&quot;red&quot;,lwd=2) Figure 3.2: t分布的pt() 3.2.3 求置信区间的qt() t分布分位函数，R中即为qt()，它可以给出一个累积分布概率达到指定值的数字。 # find t for 95% confidence interval value of t with 2.5% in each tail qt(p=0.025, df = 5, lower.tail = T) ## -2.570582 # Specifyin the x-values x_qt &lt;- seq(0.1, by = 0.01) # Applying the qt() function y_qt &lt;- qt(x_qt, df = 5) # Plotting plot(y_qt, main = &quot;t quantile function example&quot;, las = 1,col=&quot;red&quot;,lwd=2) Figure 3.3: t分布的qt() 3.2.4 指定t分布函数rt() rt()函数用于生成符合指定观测数目和自由度的t分布的随机数，默认是。 set.seed(61) # Setting sample size n &lt;- 10000 # Using rt() to drawing N log normally distributed values y_rt &lt;- rt(n, df = 5) # Plotting a histogram of y_rt hist(y_rt, breaks = 100, main = &quot;Randomly drawn t density&quot;, freq=FALSE, col=&quot;#A8D6FF&quot;,xlim=c(-10,10),ylim=c(0,0.4)) lines(density(y_rt), col=&quot;red&quot;, lwd=2) Figure 3.4: t分布的rt() 3.2.5 参数估计 参数估计是指用样本参数(统计量)推断总体参数，有点值估计(Point estimation)和区间估计(Interval estimation)两种。 点值估计就是用相应样本统计量简单直接的作为总体参数的估计值，如用\\(\\bar{X}\\)估计\\(μ\\)，用\\(S\\)估计\\(\\sigma\\)。 案例 某开发团队对开发App进行了改版迭代，现在有以下两个版本 + 版本1: 首页为一屏课程列表 + 版本2：首页为信息流 如果我们想区分两个版本，哪个版本用户更喜欢，转化率会更高。我们就需要对总体（全部用户）进行评估， 但是并不是全部存量用户都会访问App，并且每天还会新增很多用户，所以我们无法对总体（全部用户）进行评估， 我们只能从总体的用户中随机抽取样本（访问App）的用户进行分析，用样本数据表现情况来充当总体数据表现情况， 以此来评估哪个版本转化率更高。 区间估计是按预先给定概率(\\(1-\\alpha\\))，通过特定的分布函数来计算确定的未知总体参数的范围。该范围称为参数的可信区间或 置信区间(Confidence bound/Confidence interval，CI)，预先设定的概率\\((1-\\alpha)\\)称为可信度或置信度(Confidence level), 通常取值95%或99%，如果特殊说明，一般是双侧95%。可信区间是两个字确定的范围，其中较小的值称为可信下限(Lower limit，L)， 较大值称为可行上限(Upper limit，U)，表示为开区间(L，U)。 3.2.5.1 总体均数可信区间 可信区间的计算是从已知总体中进行固定样品含量的重复随机抽样实验，根据每个样本计算的可信区间。可信区间的好坏取决于可信度\\(1-\\alpha\\) 的大小；是区间的宽度，通过增加样本含量可以缩减区间宽度。 1.单一总体均数可信区间 a.\\(\\sigma\\)未知且\\(n\\)较小(n60)时，按照t分布计算。 b.\\(\\sigma\\)未知且\\(n\\)较大(n60)时，按照标准正态分布(即u分布或Z分布)计算。 计算公式和示例可参见教材或者百科资料。 2.两总体均数之差的可信区间 参见教材或者百科资料。 3.2.6 假设检验 从总体中随机抽样，由样本信息推断总体特征，除前面所讲的参数估计方法外，在实际应用中还会遇到这样的问题：某一样本均数是 否来自于某已知数的总体?两个不同样本均数是否来自均数不相等的总体等要回答这类问题,除可用前面参数估计的方法外， 更多的是用统计推断的另一方面——假设检验 (Hypothesis test)来解决，比如下面两个案例： 案例3-5 某医生测量了36名从事铅作业男性工人的血红蛋白含量,算得其均数为130.83 g/L，标准差为25.74 g/L。问： 从事铅作业男性工人的血红蛋白含量均数(μ)是否不等于正常成年男性的均数 140 g/L (\\(μ_0\\))? 针对问题一，其目的是判断是否\\(μμ_0\\)，以给出的条件看\\(\\bar{X}\\)与已知总体均数\\(μ_0\\)不相等， 造成两者不等的原因有两种情况： 从事前作业的样品血红含量确实与正常样品不一样，即非同一总体(\\(μμ_0\\)); 因为抽样误差导致的两者不相等，两者实际为同一总体(\\(μμ_0\\))。 要判断第一种情况很困难，但可以利用反正思想从第种出发，间接判断是否\\(μμ_0\\)：假设\\(μμ_0\\)，判断由于抽样误 差造成不相等的可能行有多大？ 如果\\(\\bar{X}\\)与\\(μ_0\\)接近，其差别可用抽样误差解释，即可认为\\(\\bar{X}\\)来自\\(μ_0\\)总体。反之，相差很大， 则难以说明\\(\\bar{X}\\)来自\\(μ_0\\)总体。那么，\\(\\bar{X}\\)与\\(μ_0\\)相差多大算是抽样误差造成的呢？若假设(\\(μμ_0\\))成立， 且样本总体符合正态分布(本案例未进行进一步判断，针对实际数据情况，做假设检验前应该情况进行分布判断或转换处理，选择合适的检验方法)， 则可以用t分布(\\(t=\\frac{\\bar{X}-μ}{S/\\sqrt{n}}\\))或正态分布(\\(u=\\frac{\\bar{X}-μ}{\\sigma/\\sqrt{n}}\\)) 来计算t值或者u值。然后根据t值或u值求得P值(P-value)来判断。如果\\(\\bar{X}\\)与\\(μ_0\\)相差很大，那么t或者u值就很大， 对应P值就小；当P值小于或等于预先规定的概率值α(如0.05)时，则为小概率事件，这有理由怀疑原假设(\\(μμ_0\\))可能不成立， 认为其对立面(\\(μμ_0\\))成立，该结论的正确性冒着5%的错误风险。 3.2.6.1 假设检验的步骤 1. 建立检验假设，确定检验水准 有两种假设，即\\(H_0\\)和\\(H_1\\)： (1)\\(μμ_0\\)，即检验假设(Hypothsis under test)，称为无效假设，也叫做零假设，原假设(Null hypothsis)， 用\\(H_0\\)表示，原假设的设置一般为：等于=、大于等于&gt;=、小于等于&lt;=。 (2)\\(μμ_0\\)，即备择假设(Alternative test)，也称为对立假设，用\\(H_1\\)表示，备择假设的设置一般为：不等于、大于&gt;、小于&lt;。 对检验假设，需要注意以下几点 . 检验假设针对的是总体，而不是样本； . \\(H_0\\)和\\(H_1\\)是相互联系，对你的假设，后面的统计推断的结论是根据\\(H_0\\)和\\(H_1\\)作出的，二者缺一不可； . \\(H_0\\)为无效假设，其假定通常是：某两个(或多个)总体的参数相等，或两个总体参数之差为0，或某资料服从某一特定分布 (如正态分布，Poisson分布等)，或\\(\\cdots\\cdots\\)无效等； . \\(H_1\\)的内容直接反映呢检验的单双侧。比如案例3-5中，如果\\(μμ_0\\)，则此检验为双侧检验(Two-sided test);若\\(H_1\\)为 \\(μμ_0\\)或\\(μ小于μ_0\\)，则检验为单侧检验(One-sided test)，不仅考虑差异，而且考虑差异的方向。单双侧检验的确定， 首先需要根据专业知识，其次是根据需要解决的问题来确定。 检验水准α，也称显著性水准(Singnificance level)，它属于Ⅰ型错误的范畴，是预先规定的概率值，它确定了 小概率事件的标准。实际中常取\\(\\alpha=0.05\\)，可根据不同研究目的给予不同设置。 第I类错误和第Ⅱ类错误 为什么统计者想要拒绝的假设放在原假设呢？因为原假设备被拒绝如果出错的话，只能犯第I类错误，而犯第I类错误的概率已经 被规定的显著性水平所控制。 我们通过样本数据来判断总体参数的假设是否成立，但样本是随机抽取的，因而有可能出现小概率的错误。这种小概率错误有两种， 一种是第I类错误(也叫弃真错误，Type Ⅰ error)，另一种是第Ⅱ类错误(也叫取伪错误，Type Ⅱ error)。 第I类错误或α错误：它是指\\(H_0\\)实际上是真的，但通过假设检验后，拒绝了原假设。这是错误的， 我们拒绝了真实的原假设，所以叫弃真错误，这个错误的概率我们记为α，也就是检验水准。在假设检验之前我们会规定这个概率的大小，从而控制检验功效。 第II类错误或β错误：它是指\\(H_0\\)实际上假的，但通过假设检验显示，不拒绝原假设。这也是错误的，我们接受的原假设实际上是假的，所以叫取伪错误，这个错误的概率我们记为β。 1-β称为检验效能(Power of test)，过去称把握度。其意义为当两总体确有差异，按规定检验水准α所能发现该差异的能力。 和B一样，1-β只取单尾。如1-β = 0.90，意味着若两总体确有差别,则理论上平均每100 次检验中，有90 次能够得出差异 有统计学意义的结论。从图中可看出，α愈小，B愈大; 反之α愈大，β愈小。若要同时减小型错误a以及1型错误B，唯一的方法 就是增加样本含量n。若重点是减少第I类错误α(如一般的假设检验)，一般取 a=0.05。 若重点是减少第II类错误(如方差齐性检验，正态性检验或想用一种方法代替另一种方法的检验等)， 一般取 a = 0.10 或0.20，甚至更高。注意:拒绝\\(H_0\\)，只可能犯第I类错误，不可能第II类错误。 不拒绝\\(H_0\\)，只可能犯第II类错误，不可能犯第I类错误。 因此，原假设一般都是想要拒绝的假设，如果原假设备被错误拒绝的话，只能犯弃真错误，而犯弃真错误的概率可以用 检验水准\\(\\alpha\\)控制，对统计者来说更容易控制，将错误影响降到最小。 Figure 3.5: 第I类错误和第Ⅱ类错误 2. 计算检验统计量 应该根据变量或资料的类型，设计方案，统计推断的目的，方法的适用条件等选择检验统计量。如成组设计两样本均数的比较可根据 资料特点选用检验统计量\\(t，t&#39;，u\\)等；而成组设计两样本翻查的比较一般先用检验统计量\\(F\\)。计算这些统计量都是在\\(H_0\\)(\\(μμ_0\\))， 即假定是比较的数据来自同一总体的成立前提下算出来的。 有的检验方法无需计算检验统计量，如四个表资料。 3. 确定\\(P\\)值，做出推断结论 \\(P\\)的含义是指从\\(H_0\\)规定的总体中随机抽样，抽得等于及大于或(和)等于及小于现有样本获得的统计量(如\\(t\\)、\\(u\\)等)值的概率。 根据获得的时候概率\\(P\\)值，与之相规定的检验水准\\(\\alpha\\)进行比较，看其是否为小概率事件二得出结论。 一般来说，推断结论应包含统计结论和专业结论两部分，前者只说明差异是否有统计学意义(Statistical Significance)， 后者这是结合专业内容给出的结论解释： \\(P\\leq\\alpha\\)，则发生小概率事件，拒绝\\(H_0\\)，接受\\(H_1\\)，差异具有统计学意义。 \\(P&gt;\\alpha\\)，则不拒绝\\(H_0\\)，差异无统计学意义。\\(P&gt;\\alpha\\)也成为“无显著性”(Non-Significance,NS)，即阴性结果。 注意的是:  不拒绝\\(H_0\\)不等于接受\\(H_0\\)，虽然在逻辑上否定的否定为肯定，但在统计上是按照检验水准\\(\\alpha\\)不拒绝\\(H_0\\)，若接受\\(H_0\\) 则因为范Ⅱ型错误的概率\\(\\beta\\)未知而证据不足，以决策的观点，之客认为展示有条件“接受”，或“阴性待诊”。  作结论是，对\\(H_0\\)只能说拒绝(Reject)或者不拒绝(Not reject)\\(H_0\\)。而对\\(H_1\\)只能说接受\\(H_1\\)，其他说法俱不妥当。  差异有无统计学意义，是对样本统计量和总体参数(如\\(\\bar{X}\\)和\\(μ_0\\))，或两个，多个样本统计量(如\\(\\bar{X_1}\\)和\\(\\bar{X_2}\\))而言， 对推断两个总体参数(如\\(μ_1\\)和\\(μ_0\\)，或\\(μ_1\\)和\\(μ_2\\))而言，只能说是否相等。 拒绝域 拒绝域是由显著性水平围成的区域。拒绝域的功能主要用来判断假设检验是否拒绝原假设的。如果样本观测计算出来的 检验统计量(如t，u值)的具体数值落在拒绝域内，就拒绝原假设，否则不拒绝原假设。给定检验水准\\(\\alpha\\)后，查表就可以得到具体 临界值，将检验统计量与临界值进行比较，判断是否拒绝原假设。 3.3 t 检验 连续性数值变量资料在假设检验，最简单，常用的方法就是t检验(t-test/Student’s t-test)，实际应用时， 理清各种检验方法的用途和使用条件及注意事项。 参数检验用于在假设检验中进行具有统计意义的检验。 3.3.1 t检验与Z检验 当\\(\\sigma\\)未知且样本量n较小时(如n&lt;60)，理论上要求t检验的样本随机抽取自正态分布的总体；如果是独立两小样本量的均数比较，还要求 多对应的两总体的方差相等(\\(\\sigma_1^2=\\sigma_2^2\\))。即方差齐性。在实际应用中，路与上述条件有略偏离，对结果影响不大。当样本含量n 较大时，t值近似u值，即可适用正态分布的u检验(或Z检验)。 如果两独立样本的方差不相等(方差不齐)，可采用数据变换(如两样本几何均数的t检验，就是将原始数据对数转换后进行t检验)处理， 或采用近似t检验(Separate variance estimation t-test)，即t‘检验或秩转换的非参数检验，比如常用的Cochran&amp;Cox法和Satterthwaite法两种，还有Welch法。 t检验基本上有三种类型： 单样本t检验(One sample/gourp t-test) 配对样本t检验(Paired/matched t-test) 两种独立样本t检验(Two sample/gourp t-test) R的stats包提供了t.test()，可以用于各种t检验，如果只提供一组数据，则进行单样本t检验，如果提供两组数据， 则进行两样本t检验，主要的相关的参数是： paired参数，TRUE则进行配对t检验，FALSE 则进行两独立样本t检验。 var.equal参数，对于两独立样本t检验，还要注意方差是否齐性，TRUE则进行经典方法，FALSE则采用近似t检验， 将数据取对数处理后进行t检验，t.test()中是采用Welch t检验。 alternative参数，用来指定检验方式，默认是双侧检验(“two.sided”)，还可以是左侧检验(“less”)和右侧检验(“greater”)。 t.test()为什么用Welch t检验 配对数据我们可以把配对信息扔了，放在一起做两独立样本t检验；当然还是成对T检验好，比如病人在使用某药 物前后的指标，如果不用配对信息，则病人之间的 variance 也混进去，方差估计会大一些，使得t检验的检验效能减弱。 方差齐性样本数据，理论上我们也可以把它当做不齐的样本用t’方法处理，但是用经典方法可以检验出更小的差别。 所以如果不确定方差齐性与否的情况下(最好时进行方差齐性检验)，就用Welch t检验。因为与经典方法相比， Welch t检验的自由度会比方差齐性的经典方法要小，根据t分布特征，自由度越小，中心越平， 而尾巴越长，要观察到同样一个t值，自由度越小所计算出来的p值会越大，换句话说，自由度越小，t检验就越保守。 在方差非齐性的处理方法中，Welch 法检验又可以给出相对较高的自由度，因此t.tes()默认使用Welch t 检验的原因估计就是因为它较为保守。 3.3.2 单样本t检验 单样本t检验(One sample/gourp t-test)即已知样本均数\\(\\bar{X}\\)(代表未知总体均数\\(μ\\))与已知总体\\(μ_0\\)的比较。比如 使用《医学统计学》中的 案例3-5 的数据在R中进行单样本t检验测试。 #使用memic包读取spss的数据格式 #install.packages(&#39;memisc&#39;) library(&quot;memisc&quot;) #读取数据 home_sav&lt;-spss.system.file(&quot;ExampleData/SavData4MedSta/Exam03-05.sav&quot;) #将数据形式转换为数据框 home_df&lt;-as.data.frame(as.data.set(home_sav)) #直接使用t.test()进行计算 t.test(home_df$hb, mu=140) ## One Sample t-test ## ## data: bfc_df ## t = -2.1367, df = 35, p-value = 0.03969 ## alternative hypothesis: true mean is not equal to 140 ## 95 percent confidence interval: ## 122.1238 139.5428 ## sample estimates: ## mean of x ## 130.8333 #左侧检验 t.test(home_df$hb, mu=140, alternative = &quot;less&quot;) #右侧检验 t.test(home_df$hb, mu=140, alternative = &quot;greater&quot;) #直接计算出t值后，使用pt函数计算p值的方式 t.value &lt;- mean(home_df$hb - 140) / sd(home_df$hb) * sqrt(nrow(home_df)) #-2.136668 #双侧检验，概率值乘以2 p.value &lt;- pt(t.value, df=nrow(home_df)-1, lower.tail=T)*2 ## [1] 0.03969288 计算显示\\(P=0.03969288&lt;\\alpha=0.05\\)，可以认为一次抽样发生了小概率事件，因此拒绝原假设\\(H_0\\)， 接受\\(H_1\\)，差异有统计意义；结合案例数据意义，可以认为从事铅作业的工人的平均血红蛋白含量低于 (因为给出样本均值是小于总体均值的)正常值。 我们还可以通过绘制拒绝域和t值落点，更直观的发现t值落在左侧和右侧的拒绝域内的。 #l使用scales包中alpha函数改变颜色透明度 library(&quot;scales&quot;) t.value&lt;--2.136668 df=35 x &lt;- seq(-5,5,by=0.01) y &lt;- dt(x,df=df) #右侧p值0.95对应的t值 right &lt;- qt(0.95,df=df) #左p值0.05对应的t值 left &lt;- qt(0.05,df=df,lower.tail=T) #绘制密度曲线 plot(x,y,type=&quot;l&quot;,xaxt=&quot;n&quot;,ylab=&quot;probabilityy&quot;, xlab=expression(paste(&#39;Assumed Distribution of &#39;,bar(x))), axes=FALSE,ylim=c(0,max(y)*1.1),xlim=c(min(x),max(x)), frame.plot=FALSE) #添加坐标轴 axis(1,at=c(-5,left,right,0,5), pos = c(0,0), labels=c(expression(&#39; &#39;),expression(bar(x)[cil]), expression(bar(x)[cir]),expression(mu[0]),expression(&#39;&#39;))) axis(2,pos = c(-5,0)) #标记左侧和右侧的拒绝域 xRiReject &lt;- seq(right,5,by=0.01) yRiReject &lt;- dt(xRiReject,df=df,) xLeReject &lt;- seq(left,-5,by=-0.01) yLeReject &lt;- dt(xLeReject,df=df) #用poltgon()绘制拒绝域 polygon(c(xRiReject,xRiReject[length(xRiReject)],xRiReject[1]), c(yRiReject,0, 0), col=alpha(&quot;red&quot;,0.4),border=NA) polygon(c(xLeReject,xLeReject[length(xLeReject)],xLeReject[1]), c(yLeReject,0, 0), col=alpha(&quot;red&quot;,0.4),border=NA) #在坐标轴上添加t值标记 axis(1,at=c(t.value,-1*(t.value)), pos = c(0,0),lwd.ticks=1, labels=c( round(t.value,2),round(-1*(t.value),2))) arrows(-1*(t.value),0, -1*(t.value), 0.4, length = 0,lty =2,col=&quot;blue&quot;) arrows(t.value,0, t.value, 0.4, length = 0,lty =2,col=&quot;blue&quot;) Figure 3.6: 血红蛋白样本的单样本t检验 3.3.3 配对样本t检验 简称配对t检验(Paired/matched t-test)，也称成对t检验(注意区别于成组t检验)，适用于配对设计的计量资料。配对设计是将受试对象按照某些重要特征特征配成对子，再见没对中的 两个受试对象随机分配到两处理组。常见的配对设计主要有： 两通志受试对象配成对子，分别接受两种不同的处理； 同一受试对象分别接受两种不同处理； 同一受试对象接受一种处理前后。 使用《医学统计学》中的 案例3-6 的数据在R中进行配对样本t检验测试，案例3-6属于第2种配对设计情况。 #使用memic包读取spss的数据格式 #install.packages(&#39;memisc&#39;) library(&quot;memisc&quot;) #读取数据 bfc_sav&lt;-spss.system.file(&quot;ExampleData/SavData4MedSta/Exam03-06.sav&quot;) #将数据形式转换为数据框 bfc_df&lt;-as.data.frame(as.data.set(bfc_sav)) #直接使用t.test()进行计算，注意paired=TRUE t.test(bfc_df$x1, bfc_df$x2, paired=TRUE) ## Paired t-test ## ## data: bfc_df$x1 and bfc_df$x2 ## t = 7.926, df = 9, p-value = 2.384e-05 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.1946542 0.3501458 ## sample estimates: ## mean of the differences ## 0.2724 计算显示\\(P=2.384e-05&lt;\\alpha=0.05\\)，可以认为一次抽样发生了小概率事件，因此拒绝原假设\\(H_0\\)， 接受\\(H_1\\)，差异有统计意义；结合案例数据意义，可认为两种方法对脂肪含量的测定结果不同， 而且第一种方法的鉴定结果数值较高(mean of the differences=0.27224 &gt; 0)。 同样，可以通过绘制拒绝域和t值落点，更直观的发现t值落在左侧和右侧的拒绝域内的。 #l使用scales包中alpha函数改变颜色透明度 library(&quot;scales&quot;) t.value&lt;-7.926 df=9 x &lt;- seq(-9,9,by=0.01) y &lt;- dt(x,df=df) #右侧p值0.95对应的t值 right &lt;- qt(0.95,df=df) #左p值0.05对应的t值 left &lt;- qt(0.05,df=df,lower.tail=T) #绘制密度曲线 plot(x,y,type=&quot;l&quot;,xaxt=&quot;n&quot;,ylab=&quot;probabilityy&quot;, xlab=expression(paste(&#39;Assumed Distribution of &#39;,bar(x))), axes=FALSE,ylim=c(0,max(y)*1.1),xlim=c(min(x),max(x)), frame.plot=FALSE) #添加坐标轴 axis(1,at=c(-9,left,right,0,9), pos = c(0,0), labels=c(expression(&#39; &#39;),expression(bar(x)[cil]), expression(bar(x)[cir]),expression(mu[0]),expression(&#39;&#39;))) axis(2,pos = c(-9,0)) #标记左侧和右侧的拒绝域 xRiReject &lt;- seq(right,9,by=0.01) yRiReject &lt;- dt(xRiReject,df=df,) xLeReject &lt;- seq(left,-9,by=-0.01) yLeReject &lt;- dt(xLeReject,df=df) #用poltgon()绘制拒绝域 polygon(c(xRiReject,xRiReject[length(xRiReject)],xRiReject[1]), c(yRiReject,0, 0), col=alpha(&quot;red&quot;,0.4),border=NA) polygon(c(xLeReject,xLeReject[length(xLeReject)],xLeReject[1]), c(yLeReject,0, 0), col=alpha(&quot;red&quot;,0.4),border=NA) #在坐标轴上添加t值标记 axis(1,at=c(t.value,-1*(t.value)), pos = c(0,0),lwd.ticks=1, labels=c( round(t.value,2),round(-1*(t.value),2))) arrows(-1*(t.value),0, -1*(t.value), 0.4, length = 0,lty =2,col=&quot;blue&quot;) arrows(t.value,0, t.value, 0.4, length = 0,lty =2,col=&quot;blue&quot;) Figure 3.7: 两种方法对饮料中的脂肪含量检测的配对t检验 3.3.4 两种独立样本t检验 两种独立样本t检验又称为成组t检验((Two sample/gourp t-test)，适用于完全随机设计两样本均数比较， 通常是比较两样本所代表的总体的均数是否不同。两组完全随机设计是将受试对象完全随机分配到两个不同处理组。 当两样本含量较小(\\(n_1\\leq60,或(和)n_2\\leq60\\))，且各自的总体符合正态分布(正态分布检验)时，再根据两组 数据的方差是否一样(方差齐性，方差齐性检验)来采用不同t检验方法。 3.3.4.1 总体方差相等的t检验 library(&quot;memisc&quot;) #读取数据 bfg_sav&lt;-spss.system.file(&quot;ExampleData/SavData4MedSta/Exam03-07.sav&quot;) #将数据形式转换为数据框 bfg_df&lt;-as.data.frame(as.data.set(bfg_sav)) x &lt;- bfg_df$result[which(bfg_df$group==1)] y &lt;- bfg_df$result[which(bfg_df$group==2)] #直接使用t.test()进行计算，注意 var.equal=TRUE t.test(x,y,var.equal=TRUE) ## Two Sample t-test ## ## data: x and y ## t = -0.64187, df = 38, p-value = 0.5248 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2.326179 1.206179 ## sample estimates: ## mean of x mean of y ## 2.065 2.625 计算显示 \\(P=0.5248&gt;\\alpha=0.05\\)，因此不拒绝原假设\\(H_0\\)，差异无统计意义；结合案例数据意义， 还不能认为两种方法的预后效果不同。 3.3.4.2 t’检验 t’检验，用于总体方差不相等的t检验。当两独立小样本的均数比较，如果方差不相等(方差不齐)，可采用数据变换(如两样本几何均数的t检验， 就是将原始数据对数转换后进行t检验)处理，或采用近似t检验(Separate variance estimation t-test)，即t’检验或秩转换的非参数检验，比如常用的 Cochran&amp;Cox法 和 Satterthwaite法 两种， 还有t.teet()里面使用的Welch法。注意的是，我了解的资料显示，似乎R语言中还没有具体实现Cochran&amp;Cox法 和 Satterthwaite法的函数实现，需根据公式写代码实现，可以参考下面的代码。另外，Satterthwaite法和Welch法都是在 Cochran&amp;Cox法的检验统计量t’的基础上，进行的自由度矫正，然后得到矫正自由度后对应的t’值代替t值。 使用《医学统计学》中的 案例3-8 的数据在R中进行总体方差不相等的t检验测试。 mean_x &lt;- 1.46 mean_y &lt;- 1.13 stdev_x &lt;- 1.36 stdev_y &lt;- 0.7 nx &lt;- 20 ny &lt;- 20 #Cochran&amp;Cox法的检验统计量*t&#39;*的 cochran_test&lt;-function(mean_x,mean_y,stdev_x,stdev_y,nx,ny) { t_vul &lt;- (mean_x-mean_y)/sqrt(stdev_x^2/nx+stdev_y^2/ny) return(t_vul) } #计算t&#39;值 cochran_t&lt;-cochran_test(mean_x,mean_y,stdev_x,stdev_y,nx,ny) ## [1] 0.9648463 #计算P值 pt(cochran_t,df=nx-1,lower.tail=F)*2 ## 0.3467427 #Satterthwaite法来矫正Cochran&amp;Cox法的检验统计量*t&#39;*的自由度 sattw_df&lt;-function(stdev_x,stdev_y,nx,ny){ satt_df&lt;-(stdev_x^2/nx+stdev_y^2/ny)^2/ (((stdev_x^2/nx)^2/(nx-1))+ ((stdev_y^2/ny)^2/(ny-1))) return(satt_df) } satt_df&lt;-sattw_df(stdev_x,stdev_y,nx,ny) #这里注意的是cochran_t&gt;0，我们要计算cochran_t相关的双侧拒绝域面积，需要指定 lower.tail=F，并加倍 pt(cochran_t,satt_df,lower.tail=F)*2 #[1] 0.3427644 #Welch法来矫正Cochran&amp;Cox法的检验统计量*t&#39;*的自由度 welch_df&lt;-function(stdev_x,stdev_y,nx,ny){ welch_df&lt;-(stdev_x^2/nx+stdev_y^2/ny)^2/ (((stdev_x^2/nx)^2/(nx+1))+ ((stdev_y^2/ny)^2/(ny+1)))-2 return(welch_df) } wel_df&lt;-welch_df(stdev_x,stdev_y,nx,ny) pt(cochran_t,wel_df,lower.tail=F)*2 #[1] 0.3424925 从上面的计算过程可知，三种t’检验显示了都不拒绝原假设\\(H_0\\)，可以认为差异物统计学意义，尚不能认为两种药物 对患者的干预效果不同。但是三种发放给出的效能是不一样的，其中Welch法的最小，Cochran&amp;Cox法的最大，也就是说 Cochran&amp;Cox法更为保守。 3.3.4.3 参数估计与假设检验的联系 可信区间与假设检验的区别和联系可信区间用于说明量的大小即推断总体参数(如总体均数)的范围，而假设检验用于推断 质的不同即判断两总体参数是否不等。两者既相互联系，又有区别。 一方面，可信区间亦可回答假设检验的问题，算得的可信区间若包含了\\(H_0\\)则按检验水准a，不拒绝\\(H_0\\):若不包含\\(H_0\\)，则按检验水准a，拒绝\\(H_0\\)，接受\\(H_1\\)。 另一方面，可信区间不但能回答差别是否有统计学意义，而且还能提供比假设检验更多的信息，即提示差別有无实际的专业意义。’ Figure 3.8中的 a b c 均有统计学意义(因可信区间未包含\\(H_0\\))。但其中:a提示有实际的专业意义(因可信区间高于有实际专业意义的值)， 值得重视:b提示可能有实际专业意义；c提示无实际专业意义，该图中d、e提示差异均无统计学意义，但其中： d因可信区间较宽，样本含量过小，抽样误差太大，难于得出结论；e提示以决策的观点，可“接受”\\(H_0\\)，因为即使增加 样本含量，得到差异有统计学意义义，也无实际专业意义。 Figure 3.8: 参数估计与假设检验的联系 3.3.5 两样本方差齐性检验 前面已经提到，在进行两样本检验尤其是两小样本均数的比较时，要求相应的两总体均服从正态分布且两总体方差相等，即方差齐性： 而配对，检验则要求每对数据差值的总体服从正态分布即可。因此进行两小样本检验时，一般应先对资料进行方差齐性检验Hmogeneity of variance test)， 特别是发现两样本方差相差悬殊时，要判断两样本所代表的两总体方差是否不等。若方差齐，采用一般的t检验;若方差不齐， 则采用近似t检验(如Cochran&amp;Cox 的检验等)。必要时，也可对资料进行 正态性检验(Normality test)，但正态性检 验更多用于采用正态分布法制定参考值范围时。 两总体方差是否不等的判断过去多采用F检验(F-test)，由于该检验理论上要求资料服从正态分布，但很多资料方差不齐时， 往往不服从正态分布。因此，近年来多采用更为稳健，不依赖总体分布具体形式Levene检验(Levene’s test，1960)。 Levene检验实质上是将原始观测值\\(X_{ij}\\)转换为相应的离差\\(z_{ij}\\)(有多种去可选)， 然后再作方差分析， 它既可用于对两个总体方差进行齐性检验，也可用于对个总体方差进行齐性检验。这里仅介绍两样本方差比较的F检验。 F检验与前面介绍到的利用正态分布进行Z检验，利用t分布进行t检验一样，它是利用F分布来进行检验的。 在R中，F分布同样拥有与正态分布，t分布类似的几个函数，分别是df()，pf()，qf()和rf()， 不过F分布主要收两组样品的自由度共同影响。R中用F检验来比较两组样本方差的函数是var.test()。 注意的是，方差齐性检验中的第一类错误的控制水准一般选择0.1，即\\(\\alpha=0.1\\)，而且一般约定取较大的方差作为分子，较小的方差作为分母， 这样计算出来的[公式]，缩小了范围，这样可以方便查表做出结论。 使用《医学统计学》中的 案例3-6 和 案例3-8 的数据在R中进行总体方差齐性检验测试。 ##案例3-6 library(&quot;memisc&quot;) #读取数据 bfc_sav&lt;-spss.system.file(&quot;ExampleData/SavData4MedSta/Exam03-06.sav&quot;) bfc_df&lt;-as.data.frame(as.data.set(bfc_sav)) x &lt;- bfg_df$result[which(bfg_df$group==1)] y &lt;- bfg_df$result[which(bfg_df$group==2)] var.test(x,y) ## F test to compare two variances ## ## data: x and y ## F = 1.5984, num df = 19, denom df = 19, p-value = 0.3153 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.6326505 4.0381795 ## sample estimates: ## ratio of variances ## 1.598361 ##方法2 #用F公式来计算F值 f_val1&lt;-var(x)/var(y) ## [1] 1.598361 p_val1 &lt;- pf(f_val1, df1=length(x)-1, df2=length(y)-1, lower.tail=FALSE)*2 ## [1] 0.3152554 #将分子分母调换，需要注意lower.tail=TRUE/FALSE的设定 pf(var(y)/var(x), df1=length(y)-1, df2=length(x)-1, lower.tail=TRUE)*2 ##案例3-8 mean_x &lt;- 1.46 mean_y &lt;- 1.13 stdev_x &lt;- 1.36 stdev_y &lt;- 0.7 nx &lt;- 20 ny &lt;- 20 #根据F分布公式，计算F值 f_val&lt;-stdev_x^2/stdev_y^2 ## [1] 3.774694 p_val &lt;- pf(f_val, df1=nx-1, df2=ny-1, lower.tail=FALSE)*2 ## [1] 0.005732012 根据计算结果，案例3-6的P值 0.3153&gt;0.1，按照α=0.1的水准，不拒绝\\(H_0\\)，差异不具有统计学意义，两组数据的方差相等，应该采用经典的t检验。 案例3-8的P值 0.0057&lt;0.1，按照α=0.1的水准，拒绝\\(H_0\\)，差异具有统计学意义，两组数据的方差不相等，应该采用t’检验。 3.4 变量转换 在主要的处理以前对数据进行的一些预处理，比如数据清洗，数据整合，数据变换)等。这里主要关注统计背景下的数据转换 (Transformation)，也叫变量转换，从更广泛的意义上讲，变量转换是一种更改分布或关系的形状的替换。 实际资料若不满足正态性或(和)方差齐性的假定，尤其是小样本资料时，如用一般的,检验可能会导致偏离真实结果较远。 对于明显偏离上述应用条件的资料，可通过变量变换的方法加以改善。所谓变量变换(Variable transformation)是将原始 数据作某种函数转换,如转换为对数值等。它可使各组方差齐同, 亦可使偏态資料正态化,以满足,检验或其他统计分析方法对 资料的要求。通常情况下，适当的变显变换可同时达到上述两个目的。但变量变换后，在结果解释上不如原始观测变量直观， 比如地震震级是能量释放的数据的对数转换的结果，但是震级每相差1.0级，能量相差大约32倍； 每相差2.0级，能量相差约1000倍！ 常用的变量变换有： 对数变换(Logarithm) 平方根变换(Square root) 平方根反正弦变换(Arcsine, Arcsine-square) 倒数变换(Reciprocal) 指数变换(Exponential) 其他的(如立方根等)应根据资料性质选择适当的变量变换方法。 关于变量转换的困惑？ 转换的主要动机是更易于描述会和挖掘数据信息。 尽管转换的处理看起来不太自然，但这在很大程度上是心理上的反对。 拥有丰富的转换经验后会减少这种感觉，因为转换通常效果很好。 实际上，许多熟悉的测量单位也是转换后的数据，比如分贝， pH和地震震级的里氏标度都是为对数转换后的数据。但是，在经验丰富的数据分析人员中，转换也引起了争论。 有些人经常使用它们，其他人则少得多。 所有观点都是可以辩驳的，或者至少是可以理解的。 常用的变量变换及其适用的数据分布，或者可以参考示例图3.9： 变换前数据分布，集中前面， 使用倒数变换(Reciprocal)； 变换前数据分布，偏前， 使用对数变换(Logarithm) 变换前数据分布，偏中前的， 使用平方根变换(Square root) 变换前数据分布，偏中后， 使用平方变换(Square)，或平方根反正弦变换(Arcsine, Arcsine-square) 变换前数据分布，偏后， 使用指数变换(Exponential) 变换前，数据接近正态分布， 直接标准化 Figure 3.9: 不同转换数据大致适应的数据分布情况, 右图来自Stevens J P. Applied multivariate statistics for the social sciences[M]. Routledge, 2012. 下面以介绍最常用的 对数变换做一个比较详细的示例，其他转换的逻辑是相同的，只是具体形式有所差别罢，故不累述。 3.4.1 对数变换 对数是指对变量x的作10，或者2，或者自然对数e 为底的对数，对分布形状有很大影响的强变换。 它通常用于减少右偏斜，并且通常适用于测量变量(一般是正态分布的)，不能应用于零或负值。 对数刻度上的一个单 位表示与所使用的对数的底数相乘，数增长或下降。 对数变换适用于: 对数正态分布资料，即原始数据的效应是相乘时，如抗体滴度；食品、蔬菜、水果 中农药的残留量；环境中某些有毒有害物质的含量；某些疾病的潜伏期等资料；各样本标准差与均数成 比例或变异系数是常数或接近某一常数的资料。基本形式有： \\[ X&#39;= \\lg X \\] \\[X&#39;= \\lg(X+K) , (当原始数据较小或有0值时，k=1；K还可以是负数)\\] 在R中进行日志记录的基本方法是使用log()函数，格式为log(value,base)， 该函数返回以base为底的value的对数。 默认情况下，此函数产生自然对数值(即默认base=e)。以2为底和以10为底的函数分别为log2()，log10()。 下面是单样本数据的对数转换示例： #install.packages(&quot;openintro&quot;,&quot;e1071&quot;,&quot;pryr&quot;) #使用mammals数据集测试 library(openintro) #e1071包中的skewness()计算偏斜度 library(e1071) #使用pryr包中的绘图对象保存方案 library(pryr) skewness(mammals$body_wt) #使用log()对body_wt数据进行转换 loged_bd_wt &lt;- log(mammals$body_wt) #skewness()计算偏斜度 skewness(loged_bd_wt) ##[1] 0.1453599 p1.pryr %&lt;a-% { hist(mammals$body_wt,breaks = 200,freq=FALSE, xlim=c(min(mammals$body_wt),max(mammals$body_wt)),main=&quot;Bodt wt. 数据分布&quot;) lines(density(mammals$body_wt), col=&quot;red&quot;, lwd=1) } p2.pryr %&lt;a-% { hist(loged_bd_wt,breaks = 200,freq=FALSE, xlim=c(min(loged_bd_wt),max(loged_bd_wt)),main=&quot;经过Log转换后Bodt wt. 数据分布&quot;) lines(density(loged_bd_wt), col=&quot;red&quot;, lwd=1) } split.screen(c(1, 2)) screen(1) p1.pryr screen(2) p2.pryr Figure 3.10: log转换前后的Mammal数据分布 下面是两组样本数据的对数转换示例，在mammals$body_wt数据上结合mammals$brain_wt数据： #使用log()对brain_wt数据进行转换 loged_br_wt &lt;- log(mammals$brain_wt) p3.pryr %&lt;a-% { plot(mammals$body_wt,mammals$brain_wt,main=&quot;body_wt vs brain_wt&quot;,col=&quot;red&quot;,pch=16) } p4.pryr %&lt;a-% { plot(loged_bd_wt,loged_br_wt,main=&quot;body_wt vs brain_wt after both loged&quot;,col=&quot;red&quot;,pch=16) } split.screen(c(1, 2)) screen(1) p3.pryr screen(2) p4.pryr Figure 3.11: log转换前后的body_wt vs brain_wt 在建立预测模型时，数据转换也可以起到很大效果。我们可以看看用mammals$body_wt和mammals$brain_wt来构建线性模型时，使用对数转换前后的残差(Residual standard error)变化。 计算结果显示，数据转换前的预测模型的残差是334.7，对数转换后的预测模型的残差是0.6943，相比转换前的要小非常多了。 lm.model &lt;- lm(mammals$brain_wt ~ mammals$body_wt) lm_log.model &lt;- lm(loged_br_wt ~ loged_bd_wt) summary(lm.model) ## Call: ## lm(formula = mammals$brain_wt ~ mammals$body_wt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -810.07 -88.52 -79.64 -13.02 2050.33 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 91.00440 43.55258 2.09 0.0409 * ## mammals$body_wt 0.96650 0.04766 20.28 &lt;2e-16 *** ## --- ## Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 ## ## Residual standard error: 334.7 on 60 degrees of freedom ## Multiple R-squared: 0.8727, Adjusted R-squared: 0.8705 ## F-statistic: 411.2 on 1 and 60 DF, p-value: &lt; 2.2e-16 summary(lm_log.model) ## Call: ## lm(formula = loged_br_wt ~ loged_bd_wt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.71550 -0.49228 -0.06162 0.43597 1.94829 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.13479 0.09604 22.23 &lt;2e-16 *** ## loged_bd_wt 0.75169 0.02846 26.41 &lt;2e-16 *** ## --- ## Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 ## ## Residual standard error: 0.6943 on 60 degrees of freedom ## Multiple R-squared: 0.9208, Adjusted R-squared: 0.9195 ## F-statistic: 697.4 on 1 and 60 DF, p-value: &lt; 2.2e-16 "],["第四章-多个样本均数比较的方差分析.html", "Chapter 4 第四章 多个样本均数比较的方差分析 4.1 方差分析", " Chapter 4 第四章 多个样本均数比较的方差分析 日期: 2020-11-18 作者：wxhyihuan 4.1 方差分析 T检验只能比较两组样本均值，对于多组的样本处理就需要用方差分析(Analysis of variance. ANOVA)。 在进行科学研究时，有时要按实验(对人称为试验)设计将所研究的对象分为多个处理组施加不同的干预(比如治疗某种疾病的方式)，施加的干预为处理， 处理因素(Treatment，如用药处理，手术处理，药品剂量等)至少有两个水平(Level，比如药物种类有A，B，C三种，即为3个水平)。这类科研资料的统计分析， 是通过所获得的样本信息来推断各处理组均数 间的差别是否有统计学意义，即处理有无效果。常采用 的统计分析方法为方差分析，由英国统计学家R. A. Fisher 首创， 为纪念 Fisher.以F命名，故方差分析又称F检验，也称为 “变异数分析”。 F检验与前面的t检验或者Z检验类似，也有自己的概率分布基础，即方差分析是依靠F-分布为概率分布的依据， 利用离均差平方和(Sum of square of deviations from mean,SS)与自由度(Degree of freedom, df)所计算的组间与组内均方(Mean of square,MS)估计出F值和P值，结合检验水准\\(\\alpha=0.05\\)判断检验结果。 若有统计学意义(\\(P值\\le0.05\\))，则拒绝原假设\\(H_0(μ_0=μ_1=μ_2=μ_3=\\cdots)\\)，接受\\(H_1\\)(\\(μ\\)不完全相等)，即各样本不是来自不完全相同的总体； 反之，若没有统计学意义(\\(P值&gt;0.05\\))，则不拒绝原假设\\(H_0(μ_0=μ_1=μ_2=μ_3=\\cdots)\\)，即还不能确定各样本是来自不完全相同的总体； 4.1.1 F分布 F分布定义是设\\(X\\)、\\(Y\\)为两个独立的随机变量，\\(X\\)服从自由度为k1的卡方分布， \\(Y\\)服从自由度为k2的卡方分布，这两个独立的卡方分布除以各自的自由度后的比率这一统计量的分布，即服从F-分布（F-distribution）， 即： \\[F=\\frac{U_1/d_1}{U_2/d_2}\\] \\(U_1\\)和\\(U_2\\)分别是自由度(Degree of freedom, df)为d1和d2的卡方分布，\\(U_1=\\sum_{i=0}^nX_i^2\\)，\\(U_2=\\sum_{i=0}^nY_i^2\\)；或者 \\[\\frac{S_1^2/d_1}{\\sigma_1^2}\\div\\frac{S_2^2/d_2}{\\sigma_2^2}\\] \\(S_1^2\\)为正态分布\\(N(0,\\sigma_1^2)\\)的\\(d_1\\)个随机变量的平方和，\\(S_2^2\\)为正态分布\\(N(0,\\sigma_2^2)\\)的\\(d_2\\)个随机变量的平方和。 F-分布对应的概率密度函数是： \\[\\begin{aligned} f(x,d_1,d_2) &amp;= \\frac{\\sqrt{\\frac{(d_{1}x)^{d_1} d_2^{d_2}}{(d_{1}x+d_2)^{d_1+d2}}}}{xB\\left(d_{1}/2,d_{2}/2\\right)}\\\\ &amp;= \\frac{1}{B\\left(d_{1}/2,d_{2}/2\\right)}\\left(\\frac{d_1}{d_2}\\right)^{\\frac{d_1}{2}}x^{\\frac{d_1}{2}-1}\\left(1+\\frac{d_1}{d_2}x\\right)^{-\\frac{d_1+d_2}{2}} \\end{aligned}\\] 在R语言中。F-分布也有几个与Z分布，t分布基本函数类似的工具函数，分别是df()，pf()，qf()和rf()。 f_val = 2.2 df1 = 10 df2 = 20 q_seq &lt;- c(0.25, 0.5, 0.75, 0.999) df(f_val, df1 = df1, df2 = df2) ## [1] 0.007858262 pf(f_val, df = df1, df2 = df2, lower.tail = TRUE) ## [1] 0.9944622 qf(q_seq, df1 = df1, df2 = df2, lower.tail = TRUE) ## [1] 0.6563936 0.9662639 1.3994874 5.0752462 x &lt;- rf(100000, df1 = df1, df2 = df2) hist(x, col=&quot;#A8D6FF&quot;, breaks = &#39;Scott&#39;, freq = FALSE, xlim = c(0,3), ylim = c(0,1), xlab = &#39;&#39;, main = &#39;Histogram for a F-distribution with df1=10, df2=20&#39;, cex.main=0.9) curve(df(x, df1 = df1, df2 = df2), from = 0, to = 3, n = 10000, col= &#39;red&#39;, lwd=2, add = T) Figure 4.1: F-分布的概率密度曲线测试 4.1.2 F检验的分类、原理及应用 4.1.2.1 分类 方差分析的基本运算概念下，依照所感兴趣的因子数量而可分三大类： 单因子方差分析(One-way ANOVA) 双因子方差分析(Two-way ANOVA) 多因子方差分析(Multi-way ANOVA) 如果依照因子的特性不同而有三种型态，分别是： 固定效应方差分析(Fixed-effect ANOVA) 随机效应方差分析(Random-effect ANOVA) 混合效应方差分析(Mixed-effect ANOVA) 一般的，按照因子数量的分类进行区分使用情况比较常见，这里借用单因素方差分析(One-way ANOVA)介绍方差分析的基本思想 4.1.2.2 原理 ANOVA通过分析方差来推断均值是否和总体有显著性差异(注意：虽然叫做方差分析，但是它的目的是检验每个组的平均数是否相同)。 ANOVA把方差分为处理因素(Treatment effect，真实差异)和误差(Error effect，抽样误差或个体差异)两个来源，两个方差的比值服从F分布，因为方差本身 就是个体和均值差平方和，所以对方差组成的分析能够反映均值的差异。处理效应(Treatment effect)是不同组的均值间的差异，误差(Error effect)是组内 个体间的差异，习惯性地称前者为组间(Between)差异，后者为组内(Wthin)差异。 例如，在工业生产或实验研究中，为了比较药物X，Y，Z对治疗某疾病的疗效，我们将实验对象分成三组，分别记录服用X，Y，Z三种药物的治疗效果，并依次得到三组样本如下： \\[\\begin{aligned} &amp; X_1,X_2,X_3,\\cdots,X_{n1};\\\\ &amp; Y_1,Y_2,Y_3,\\cdots,Y_{n2};\\\\ &amp; Z_1,Z_2,Z_3,\\cdots,Z_{n3}; \\end{aligned}\\] 通过这些实验数据，我们希望回答：三种药物对治疗该疾病有没有显著差异；如果有差异，哪种药物治疗效果最好？ 这个例子中，药物称为处理因素，X，Y，Z称为该因素的水平。这个实验只涉及单个处理因素——“药物”，我们称之为单因素实验，对应的方差分析处理叫单因子方差分析(One-way ANOVA)。此外，如果比较不同的药物和 剂量对疗效的影响，这就是双因素实验，对应的方差分析叫双因子方差分析(Two-way ANOVA)，由此类似可推广到多因素实验和多因子方差分析(Multi-way ANOVA)。 示例中，我们记总均数\\(\\bar{M}\\)，各分组(水平)的均数为\\(\\bar{X}\\)，\\(\\bar{Y}\\)，\\(\\bar{Z}\\)，总样本个数\\(N=n_1+n_2+n_3\\)， 分组(水平)个数记为g，本例中g=3。 \\[\\bar{M}=\\frac{\\sum_{i=0}^{n1}X_{n1}+\\sum_{i=0}^{n2}Y_{n2}+\\sum_{i=0}^{n3}Z_{n3}}{n_1+n_2+n_3}\\] 把所有分组的混在一起，当成一个样本，总的方差的自由度为\\(v_t=N-1\\)，(\\(SS_{tol}\\)总变异)公式为： \\[\\begin{aligned} SS_{t} &amp;= \\sum_{i=1}^g\\sum_{j=1}^{n_i}(X_{ij}-\\bar{X})\\\\ &amp;= \\sum_{i=1}^g\\sum_{j=1}^{n_i}X_{ij}^2-(\\sum_{i=1}^g\\sum_{j=1}^{n_i}X_{ij})^2/N \\end{aligned}\\] 组间方差的自由度为\\(v_b=g-1\\)，组间方差\\(SS_{b}\\)为： \\[\\begin{aligned} SS_{b} &amp;= \\sum_{i=1}^gn_i(X_{i}-\\bar{X})\\\\ &amp;= \\sum_{i=1}^g\\frac{(\\sum_{j=1}^nX_{ij})^2}{n_i}-(\\sum_{i=1}^g\\sum_{j=1}^{n_i}X_{ij})^2/N \\end{aligned}\\] 组内方差的自由度为\\(v_w=N-g\\)，组内方差SS_{w}(有的也记为SS_{error})为： \\[\\begin{aligned} SS_{w} &amp;= \\sum_{i=1}^g\\sum_{j=1}^{n_i}(X_{ij}-\\bar{X_i})^2 \\end{aligned}\\] 总的方差与组间方差和组内方差的关系： \\[SS_{t}=SS_{b}+SS_{w}\\] 总的方差与组间方差和组内方差各自的自由度之间的关系： \\[v_{t}=v_{b}+v_{w}\\] 变异程度除与离均差平方和的大小有关外，还与其自由度有关，由于各部分自由度不相等，因此各部分离均差平方和不能直接比较，须将各部分离均差平方和除以相应的自由度，其比值称为均方差，简称均 方(Mean of square,MS)。组间均方和组内均方的计算公式为: \\[\\begin{aligned} MS_{b} &amp;= \\frac{SS_b}{v_b}\\\\ MS_{w} &amp;= \\frac{SS_t}{v_t} \\end{aligned}\\] 组间均方和组内均方的比值，符合F分布，由此可计算F统计量： \\[\\begin{aligned} F &amp;= \\frac{MS_b}{MS_w}\\\\ &amp;= \\frac{\\frac{SS_b}{v_b}}{\\frac{SS_t}{v_t}} \\end{aligned}\\] 如果F值接近于1，即组间均方和组内均方越接近的话，就没有理由拒绝\\(H_0\\)；反之，F值越大，拒绝\\(H_0\\)的理由越充分。数理统计的理论证明，当\\(H_0\\)成立时，F统计量服从F分布。 方差分析是单侧F检验，可查出按α水准(一般取α = 0.05)F分布的单尾界值F(α,v1,v2)作为判断统计量F大小的标准。 若根据实验结果计算的F值偏大，如FF(α,v1,v2)时，则P&lt;0.05，拒绝\\(H_0\\)，接受\\(H_1\\)，说明各样本来自不全相同的 总体，即认为各样本的总体均数不全相等。反之，当F&lt;F(α,v1,v2)时，则P&gt;0.05.不拒绝\\(H_0\\)，还不能下各样本的总体均数 不全相等的结论。 4.1.2.3 F-检验的原理示例 上面提到治疗某疾病研究药物处理因素在三种X，Y，Z三种水平的是否有差异，在假设\\(H_0：μ_0=μ_1=μ_2=μ_3\\)成立的情况下， 我们大概可以做出类似下面这演的示例图。 Figure 4.2: 三种药物来自同一总体的假设模拟即MSb，MSw示例 根据F检验的原理，F值是组间均方\\(MS_b\\)和组内均方\\(MS_w\\)得比值，由此大概有三种情况： A. \\(MS_bMS_w\\)，F1 这个时候MSB和MSE比较近似，可能是每组的平均值很集中，且每组方差很小；或者每组的方差较大，平均值也都离的不太远。 总之，我们无法很好的剥离出某一组的分布。所以，我们同样无法拒绝\\(H_0：μ_0=μ_1=μ_2=μ_3\\)。 Figure 4.3: 三种药物来自同一总体的假设模拟，MSbMSw示例 B. \\(MS_b&gt;&gt;MS_w\\)，F&gt;1 这个情况说明，至少有一个分布相对其他分布较远，且每个分布都非常集中，即每个分组的分布方差差别较小。所以，我们不能得出三个分布都有相同的均值， 于是拒绝\\(H_0：μ_0=μ_1=μ_2=μ_3\\)。 Figure 4.4: MSb&gt;&gt;MSw示例 C. \\(MS_b&lt;&lt;MS_w\\)，F&lt;1 这个情况有两种可能，当然也可以是这两种可能的混合。一是每组的平均值都相对集中，二是每组的方差很大，导致我们无法把每组分开。所以我们无法拒绝\\(H_0：μ_0=μ_1=μ_2=μ_3\\)。 两个极端的例子： Figure 4.5: MSb&lt;&lt;MSw示例 4.1.2.4 F-检验的前提 F-检验是建立在一些假设基础上的，如果你的实验不能满足F-检验的假设，那你需要考虑别的分析方法或者改变实验设计。F-检验有主要有以下3个假设： 方差的齐性，可以理解为每组样本背后的总体(也叫族群)都有相同的方差 族群遵循正态分布 每一次抽样都是独立的，比如每个病人只能提供一个数据。对于一些一个样本需要提供多个数据的情况，有其他相应的F检验方法。 4.1.2.5 F-检验的应用 F检验的主要有如下几种： 方差齐性检验(F-test of equality of variances) 方差分析(Analysis of Variance, ANOVA) 线性回归方程整体的显著性检验 4.1.3 完全随机设计资料的方差分析 完全随机设计(Completely random design)是采用完全随机化的分组方法，将全部实验对象分配到g个组(水平组)，各组分别接受不同的处理， 实验结束后比较各组均数之间的差别有无统计学意义，推论因素的效应。 使用《医学统计学》中的 案例4-2 的数据在R中进行总体方差齐性检验测试。 ##案例4-2 library(&quot;memisc&quot;) #读取数据 rdl_sav&lt;-spss.system.file(&quot;ExampleData/SavData4MedSta/Exam04-02.sav&quot;) rdl_df&lt;-as.data.frame(as.data.set(rdl_sav)) ##简洁地显示任意R对象的结构 str(rdl_df) ## &#39;data.frame&#39;: 120 obs. of 2 variables: ## $ GROUP: num 1 1 1 1 1 1 1 1 1 1 ... ## $ LDL_C: num 3.53 4.59 4.34 2.66 3.59 3.13 3.3 4.04 3.53 3.56 ... ##对不规则数组应用指定的函数，快速计算每组的均值，方差，和样本大小 tapply(rdl_df$LDL_C, rdl_df$GROUP, FUN = mean) ## 1 2 3 4 ## 3.430333 2.715333 2.698000 1.966333 tapply(rdl_df$LDL_C, rdl_df$GROUP, FUN = var) ## 1 2 3 4 ## 0.5114033 0.4072464 0.2471752 0.5571757 tapply(rdl_df$LDL_C, rdl_df$GROUP, length) ## 1 2 3 4 ## 30 30 30 30 #boxplot(rdl_df$LDL_C ~ rdl_df$GROUP,col=c(2:5)) ## 使用oneway.test()函数进行F检验，注意var.equal 默认是 FALSE，也就是说方差可以不相等，但是提供的信息相对较少。 oneway.test(rdl_df$LDL_C ~ rdl_df$GROUP,var.equal=T) ## One-way analysis of means ## ## data: rdl_df$LDL_C and rdl_df$GROUP ## F = 24.884, num df = 3, denom df = 116, p-value = 1.674e-12 oneway.test(rdl_df$LDL_C ~ rdl_df$GROUP,var.equal=F) ## One-way analysis of means (not assuming equal variances) ## ## data: rdl_df$LDL_C and rdl_df$GROUP ## F = 19.665, num df = 3.000, denom df = 63.592, p-value = ## 3.924e-09 #使用aov()函数进行F检验，可以获取完整地参数信息，这里要注意aov()里面提供的group信息最好不要是数值形式的分组，否则结果非不一致，可以用 #as.character()将数字转换为字串形式的再使用 aov.out = aov(rdl_df$LDL_C ~ as.character(rdl_df$GROUP)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## as.character(rdl_df$GROUP) 3 32.16 10.719 24.88 1.67e-12 *** ## Residuals 116 49.97 0.431 ## --- ## Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 ## &gt; aov.out ## Call: ## aov(formula = rdl_df$LDL_C ~ as.character(rdl_df$GROUP)) ## ## Terms: ## as.character(rdl_df$GROUP) Residuals ## Sum of Squares 32.15603 49.96702 ## Deg. of Freedom 3 116 ## ## Residual standard error: 0.6563156 ## Estimated effects may be unbalanced summary(aov.out) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## as.character(rdl_df$GROUP) 3 32.16 10.719 24.88 1.67e-12 *** ## Residuals 116 49.97 0.431 ## --- ## Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 boxplot(rdl_df$LDL_C ~ rdl_df$GROUP,col=c(2:5),ylab=&quot;rdl value&quot;,xlab=&quot;Group info&quot;) Figure 4.6: 案例 04-02 120例数据的箱线图预览 Table 4.1: 案例04-02f检验结果 组间 组内 自由度 3.000 116 SS 32.156 49.96702 MS 10.719 0.430750172413793 F值 24.884 P值 0.000 根据计算结果，F值=24.884&gt;\\(F_{(0.01,(3,116))}\\)，P值&lt;0.01&lt;0.05，按照α=0.05的检验水准，拒绝\\(H_0\\)，接受 \\(H_1\\)，认为4个处理组的总体均数不全相等。 "]]
